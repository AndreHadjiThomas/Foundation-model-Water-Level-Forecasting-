{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **1. Install Required Libraries and Import Modules**\n",
    "\n",
    "This section installs the necessary libraries and imports the required modules for data manipulation, modeling, and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary libraries\n",
    "!pip install timesfm\n",
    "\n",
    "# Import required libraries for data manipulation, modeling, and visualization\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import timesfm\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **2. Data Loading and Preprocessing**\n",
    "\n",
    "In this section, we load the dataset, preprocess the data, and prepare it for time series forecasting. This includes mounting Google Drive to access the data and handling missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive to access data stored in it\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Load the dataset (CSV file with discharge data)\n",
    "data_file = '/content/drive/MyDrive/Biomet/historique_demande_electricite_quebec_daily.csv'\n",
    "df = pd.read_csv(data_file)\n",
    "\n",
    "# Convert 'date' column to datetime format and sort data\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df = df.sort_values('date').reset_index(drop=True)\n",
    "\n",
    "# Drop rows with missing discharge observations and reset index\n",
    "df = df.dropna(subset=['discharge_spec_obs', 'discharge_spec_sim_lstm']).reset_index(drop=True)\n",
    "\n",
    "# Add a unique identifier and prepare time series data\n",
    "df['unique_id'] = 1\n",
    "df['ds'] = df['date']\n",
    "df['wl'] = df['discharge_spec_obs']\n",
    "\n",
    "# Prepare the DataFrame for the time series\n",
    "time_series_df = df[['unique_id', 'ds', 'wl']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **3. Time Series Data Splitting and Visualization**\n",
    "\n",
    "In this section, we split the data into training, validation, and test sets. We also visualize the water level data over time to better understand the trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the indices for splitting the time series data\n",
    "n = len(time_series_df)  # Total number of data points\n",
    "train_idx = int(0.8 * n)  # First 80% for training\n",
    "valid_idx = int(0.9 * n)  # Next 10% for validation\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "# Plot the water level data\n",
    "plt.plot(time_series_df['ds'], time_series_df['wl'], label=\"Water Level\", color='b')\n",
    "\n",
    "# Shade the training, validation, and testing sets\n",
    "plt.axvspan(time_series_df['ds'].iloc[0], time_series_df['ds'].iloc[train_idx], color='lightblue', alpha=0.4, label=\"Training Set\")\n",
    "plt.axvspan(time_series_df['ds'].iloc[train_idx], time_series_df['ds'].iloc[valid_idx], color='lightgreen', alpha=0.4, label=\"Validation Set\")\n",
    "plt.axvspan(time_series_df['ds'].iloc[valid_idx], time_series_df['ds'].iloc[-1], color='lightcoral', alpha=0.4, label=\"Testing Set\")\n",
    "\n",
    "# Add labels, title, and legend\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Water Level\")\n",
    "plt.title(\"Measured Water Level Over the Years at Gauge 01BO001\")\n",
    "plt.legend()\n",
    "\n",
    "# Adjust layout to prevent overlap\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **4. Initialize TimesFM Model**\n",
    "\n",
    "In this section, we initialize the TimesFM model, specifying the hyperparameters such as batch size, forecast horizon, and context length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfm = timesfm.TimesFm(\n",
    "    hparams=timesfm.TimesFmHparams(\n",
    "        backend=\"gpu\",\n",
    "        per_core_batch_size=16,\n",
    "        horizon_len=3,  # 3-day forecast horizon\n",
    "        context_len=352,\n",
    "    ),\n",
    "    checkpoint=timesfm.TimesFmCheckpoint(\n",
    "        huggingface_repo_id=\"google/timesfm-1.0-200m-pytorch\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **5. Rolling Forecast Using TimesFM**\n",
    "\n",
    "This section performs the rolling forecast. We predict 3 days at a time and move the prediction window one day at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare results list to store forecasted values\n",
    "results = []\n",
    "\n",
    "# Rolling forecast: predict 3 days at a time, advancing by 1 day in each loop\n",
    "for i in range(len(test_df) - 2):  # Ensure there's enough data for 3-day forecasts\n",
    "    # Forecast the next three days\n",
    "    forecast_df = tfm.forecast_on_df(\n",
    "        inputs=train_df,\n",
    "        freq=\"d\",  # daily input data\n",
    "        value_name=\"wl\",\n",
    "        num_jobs=-1,\n",
    "    )\n",
    "\n",
    "    # Extract h1, h2, h3 from the forecast\n",
    "    h1, h2, h3 = forecast_df['timesfm'].iloc[0], forecast_df['timesfm'].iloc[1], forecast_df['timesfm'].iloc[2]\n",
    "\n",
    "    # Append to results with corresponding observation for the first day of each period\n",
    "    results.append({\n",
    "        'date': test_df['ds'].iloc[i],\n",
    "        'h1': h1,\n",
    "        'h2': h2,\n",
    "        'h3': h3,\n",
    "        'obs': test_df['wl'].iloc[i]  # Observed value on the first day of the forecast period\n",
    "    })\n",
    "\n",
    "    # Update the training data with the actual observation of the current day\n",
    "    train_df = pd.concat([train_df, test_df.iloc[[i]]], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **6. Processing Forecast Results**\n",
    "\n",
    "Here, we process the forecasted results, shifting the forecasted values (h1, h2, h3) by one day to align with the observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert results list to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Shift the forecasted values (h1, h2, h3) by one day\n",
    "results_df[['h1', 'h2', 'h3']] = results_df[['h1', 'h2', 'h3']].shift(-1)\n",
    "results_df = results_df[:-1]\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(results_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **7. Visualization of Forecast vs Observed Data**\n",
    "\n",
    "This section visualizes the forecasted values against the observed water levels for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot forecasted values against observed values\n",
    "def plot_forecast_vs_observed(results_df):\n",
    "    \"\"\"\n",
    "    Visualizes the observed water levels and the corresponding forecasted values for the 1st, 2nd, and 3rd days.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    plt.plot(results_df['date'], results_df['obs'], label=\"Observed\", color='b')\n",
    "    plt.plot(results_df['date'], results_df['h1'], label=\"Forecast (Day 1)\", color='r')\n",
    "    plt.plot(results_df['date'], results_df['h2'], label=\"Forecast (Day 2)\", color='orange')\n",
    "    plt.plot(results_df['date'], results_df['h3'], label=\"Forecast (Day 3)\", color='green')\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Water Level\")\n",
    "    plt.title(\"Three-Day-Ahead TimesFM Rolling Forecast vs Observed Water Levels\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Call the plot function to display forecast vs observed comparison\n",
    "plot_forecast_vs_observed(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **8. Model Evaluation - Nash-Sutcliffe and Kling-Gupta Efficiency**\n",
    "\n",
    "In this section, we evaluate the performance of the forecast using two efficiency metrics: Nash-Sutcliffe Efficiency (NSE) and Kling-Gupta Efficiency (KGE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate Nash-Sutcliffe Efficiency (NSE)\n",
    "def nse(observed, forecasted):\n",
    "    numerator = np.sum((observed - forecasted) ** 2)\n",
    "    denominator = np.sum((observed - np.mean(observed)) ** 2)\n",
    "    return 1 - (numerator / denominator)\n",
    "\n",
    "# Function to calculate Kling-Gupta Efficiency (KGE)\n",
    "def kge(observed, forecasted):\n",
    "    # Calculate correlation coefficient\n",
    "    r = np.corrcoef(observed, forecasted)[0, 1]\n",
    "\n",
    "    # Calculate variability ratio (alpha)\n",
    "    alpha = np.std(forecasted) / np.std(observed)\n",
    "\n",
    "    # Calculate bias ratio (beta)\n",
    "    beta = np.mean(forecasted) / np.mean(observed)\n",
    "\n",
    "    # Calculate KGE\n",
    "    kge_value = 1 - np.sqrt((r - 1) ** 2 + (alpha - 1) ** 2 + (beta - 1) ** 2)\n",
    "    return kge_value\n",
    "\n",
    "# Section 11: Calculate and Print NSE and KGE for Forecasts\n",
    "observed = results_df['obs'].values\n",
    "\n",
    "# Calculate NSE and KGE for the 1st day forecast (h1)\n",
    "forecasted_h1 = results_df['h1'].values\n",
    "nse_h1 = nse(observed, forecasted_h1)\n",
    "kge_h1 = kge(observed, forecasted_h1)\n",
    "\n",
    "# Print NSE and KGE values\n",
    "print(f\"Nash-Sutcliffe Efficiency (NSE) for 1st day forecast: {nse_h1}\")\n",
    "print(f\"Kling-Gupta Efficiency (KGE) for 1st day forecast: {kge_h1}\")\n",
    "\n",
    "# Repeat for the 2nd day (h2) and 3rd day (h3) forecasts\n",
    "forecasted_h2 = results_df['h2'].values\n",
    "forecasted_h3 = results_df['h3'].values\n",
    "\n",
    "nse_h2 = nse(observed, forecasted_h2)\n",
    "kge_h2 = kge(observed, forecasted_h2)\n",
    "\n",
    "nse_h3 = nse(observed, forecasted_h3)\n",
    "kge_h3 = kge(observed, forecasted_h3)\n",
    "\n",
    "# Print results for each forecast horizon\n",
    "print(f\"Nash-Sutcliffe Efficiency (NSE) for 2nd day forecast: {nse_h2}\")\n",
    "print(f\"Kling-Gupta Efficiency (KGE) for 2nd day forecast: {kge_h2}\")\n",
    "print(f\"Nash-Sutcliffe Efficiency (NSE) for 3rd day forecast: {nse_h3}\")\n",
    "print(f\"Kling-Gupta Efficiency (KGE) for 3rd day forecast: {kge_h3}\")"
   ]
  }
 ]
}
