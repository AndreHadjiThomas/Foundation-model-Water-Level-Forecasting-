{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ulb4Gz3SFQZF",
        "outputId": "3a8892ba-9c01-46ab-e691-ed3ae92029e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'null' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-8ea9770fb450>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m   {\n\u001b[1;32m     13\u001b[0m    \u001b[0;34m\"cell_type\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"code\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m    \u001b[0;34m\"execution_count\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnull\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m    \u001b[0;34m\"metadata\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m    \u001b[0;34m\"outputs\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'null' is not defined"
          ]
        }
      ],
      "source": [
        "{\n",
        " \"cells\": [\n",
        "  {\n",
        "   \"cell_type\": \"markdown\",\n",
        "   \"metadata\": {},\n",
        "   \"source\": [\n",
        "    \"# **1. Install Required Libraries and Import Modules**\\n\",\n",
        "    \"\\n\",\n",
        "    \"This section installs the necessary libraries and imports the required modules for data manipulation, modeling, and visualization.\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": null,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"# Install necessary libraries\\n\",\n",
        "    \"!pip install timesfm\\n\",\n",
        "    \"\\n\",\n",
        "    \"# Import required libraries for data manipulation, modeling, and visualization\\n\",\n",
        "    \"import pandas as pd\\n\",\n",
        "    \"import matplotlib.pyplot as plt\\n\",\n",
        "    \"import timesfm\\n\",\n",
        "    \"import numpy as np\\n\",\n",
        "    \"import tensorflow as tf\\n\",\n",
        "    \"import matplotlib.pyplot as plt\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"markdown\",\n",
        "   \"metadata\": {},\n",
        "   \"source\": [\n",
        "    \"# **2. Data Loading and Preprocessing**\\n\",\n",
        "    \"\\n\",\n",
        "    \"In this section, we load the dataset, preprocess the data, and prepare it for time series forecasting. This includes mounting Google Drive to access the data and handling missing values.\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": null,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"# Mount Google Drive to access data stored in it\\n\",\n",
        "    \"from google.colab import drive\\n\",\n",
        "    \"drive.mount('/content/drive')\\n\",\n",
        "    \"\\n\",\n",
        "    \"# Load the dataset (CSV file with discharge data)\\n\",\n",
        "    \"data_file = '/content/drive/MyDrive/Biomet/historique_demande_electricite_quebec_daily.csv'\\n\",\n",
        "    \"df = pd.read_csv(data_file)\\n\",\n",
        "    \"\\n\",\n",
        "    \"# Convert 'date' column to datetime format and sort data\\n\",\n",
        "    \"df['date'] = pd.to_datetime(df['date'])\\n\",\n",
        "    \"df = df.sort_values('date').reset_index(drop=True)\\n\",\n",
        "    \"\\n\",\n",
        "    \"# Drop rows with missing discharge observations and reset index\\n\",\n",
        "    \"df = df.dropna(subset=['discharge_spec_obs', 'discharge_spec_sim_lstm']).reset_index(drop=True)\\n\",\n",
        "    \"\\n\",\n",
        "    \"# Add a unique identifier and prepare time series data\\n\",\n",
        "    \"df['unique_id'] = 1\\n\",\n",
        "    \"df['ds'] = df['date']\\n\",\n",
        "    \"df['wl'] = df['discharge_spec_obs']\\n\",\n",
        "    \"\\n\",\n",
        "    \"# Prepare the DataFrame for the time series\\n\",\n",
        "    \"time_series_df = df[['unique_id', 'ds', 'wl']]\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"markdown\",\n",
        "   \"metadata\": {},\n",
        "   \"source\": [\n",
        "    \"# **3. Time Series Data Splitting and Visualization**\\n\",\n",
        "    \"\\n\",\n",
        "    \"In this section, we split the data into training, validation, and test sets. We also visualize the water level data over time to better understand the trends.\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": null,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"# Determine the indices for splitting the time series data\\n\",\n",
        "    \"n = len(time_series_df)  # Total number of data points\\n\",\n",
        "    \"train_idx = int(0.8 * n)  # First 80% for training\\n\",\n",
        "    \"valid_idx = int(0.9 * n)  # Next 10% for validation\\n\",\n",
        "    \"\\n\",\n",
        "    \"plt.figure(figsize=(15, 8))\\n\",\n",
        "    \"\\n\",\n",
        "    \"# Plot the water level data\\n\",\n",
        "    \"plt.plot(time_series_df['ds'], time_series_df['wl'], label=\\\"Water Level\\\", color='b')\\n\",\n",
        "    \"\\n\",\n",
        "    \"# Shade the training, validation, and testing sets\\n\",\n",
        "    \"plt.axvspan(time_series_df['ds'].iloc[0], time_series_df['ds'].iloc[train_idx], color='lightblue', alpha=0.4, label=\\\"Training Set\\\")\\n\",\n",
        "    \"plt.axvspan(time_series_df['ds'].iloc[train_idx], time_series_df['ds'].iloc[valid_idx], color='lightgreen', alpha=0.4, label=\\\"Validation Set\\\")\\n\",\n",
        "    \"plt.axvspan(time_series_df['ds'].iloc[valid_idx], time_series_df['ds'].iloc[-1], color='lightcoral', alpha=0.4, label=\\\"Testing Set\\\")\\n\",\n",
        "    \"\\n\",\n",
        "    \"# Add labels, title, and legend\\n\",\n",
        "    \"plt.xlabel(\\\"Year\\\")\\n\",\n",
        "    \"plt.ylabel(\\\"Water Level\\\")\\n\",\n",
        "    \"plt.title(\\\"Measured Water Level Over the Years at Gauge 01BO001\\\")\\n\",\n",
        "    \"plt.legend()\\n\",\n",
        "    \"\\n\",\n",
        "    \"# Adjust layout to prevent overlap\\n\",\n",
        "    \"plt.tight_layout()\\n\",\n",
        "    \"\\n\",\n",
        "    \"# Show the plot\\n\",\n",
        "    \"plt.show()\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"markdown\",\n",
        "   \"metadata\": {},\n",
        "   \"source\": [\n",
        "    \"# **4. Initialize TimesFM Model**\\n\",\n",
        "    \"\\n\",\n",
        "    \"In this section, we initialize the TimesFM model, specifying the hyperparameters such as batch size, forecast horizon, and context length.\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": null,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"tfm = timesfm.TimesFm(\\n\",\n",
        "    \"    hparams=timesfm.TimesFmHparams(\\n\",\n",
        "    \"        backend=\\\"gpu\\\",\\n\",\n",
        "    \"        per_core_batch_size=16,\\n\",\n",
        "    \"        horizon_len=3,  # 3-day forecast horizon\\n\",\n",
        "    \"        context_len=352,\\n\",\n",
        "    \"    ),\\n\",\n",
        "    \"    checkpoint=timesfm.TimesFmCheckpoint(\\n\",\n",
        "    \"        huggingface_repo_id=\\\"google/timesfm-1.0-200m-pytorch\\\"\\n\",\n",
        "    \"    ),\\n\",\n",
        "    \")\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"markdown\",\n",
        "   \"metadata\": {},\n",
        "   \"source\": [\n",
        "    \"# **5. Rolling Forecast Using TimesFM**\\n\",\n",
        "    \"\\n\",\n",
        "    \"This section performs the rolling forecast. We predict 3 days at a time and move the prediction window one day at a time.\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": null,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"# Prepare results list to store forecasted values\\n\",\n",
        "    \"results = []\\n\",\n",
        "    \"\\n\",\n",
        "    \"# Rolling forecast: predict 3 days at a time, advancing by 1 day in each loop\\n\",\n",
        "    \"for i in range(len(test_df) - 2):  # Ensure there's enough data for 3-day forecasts\\n\",\n",
        "    \"    # Forecast the next three days\\n\",\n",
        "    \"    forecast_df = tfm.forecast_on_df(\\n\",\n",
        "    \"        inputs=train_df,\\n\",\n",
        "    \"        freq=\\\"d\\\",  # daily input data\\n\",\n",
        "    \"        value_name=\\\"wl\\\",\\n\",\n",
        "    \"        num_jobs=-1,\\n\",\n",
        "    \"    )\\n\",\n",
        "    \"\\n\",\n",
        "    \"    # Extract h1, h2, h3 from the forecast\\n\",\n",
        "    \"    h1, h2, h3 = forecast_df['timesfm'].iloc[0], forecast_df['timesfm'].iloc[1], forecast_df['timesfm'].iloc[2]\\n\",\n",
        "    \"\\n\",\n",
        "    \"    # Append to results with corresponding observation for the first day of each period\\n\",\n",
        "    \"    results.append({\\n\",\n",
        "    \"        'date': test_df['ds'].iloc[i],\\n\",\n",
        "    \"        'h1': h1,\\n\",\n",
        "    \"        'h2': h2,\\n\",\n",
        "    \"        'h3': h3,\\n\",\n",
        "    \"        'obs': test_df['wl'].iloc[i]  # Observed value on the first day of the forecast period\\n\",\n",
        "    \"    })\\n\",\n",
        "    \"\\n\",\n",
        "    \"    # Update the training data with the actual observation of the current day\\n\",\n",
        "    \"    train_df = pd.concat([train_df, test_df.iloc[[i]]], ignore_index=True)\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"markdown\",\n",
        "   \"metadata\": {},\n",
        "   \"source\": [\n",
        "    \"# **6. Processing Forecast Results**\\n\",\n",
        "    \"\\n\",\n",
        "    \"Here, we process the forecasted results, shifting the forecasted values (h1, h2, h3) by one day to align with the observations.\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": null,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"# Convert results list to DataFrame\\n\",\n",
        "    \"results_df = pd.DataFrame(results)\\n\",\n",
        "    \"\\n\",\n",
        "    \"# Shift the forecasted values (h1, h2, h3) by one day\\n\",\n",
        "    \"results_df[['h1', 'h2', 'h3']] = results_df[['h1', 'h2', 'h3']].shift(-1)\\n\",\n",
        "    \"results_df = results_df[:-1]\\n\",\n",
        "    \"\\n\",\n",
        "    \"# Display the resulting DataFrame\\n\",\n",
        "    \"print(results_df.head())\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"markdown\",\n",
        "   \"metadata\": {},\n",
        "   \"source\": [\n",
        "    \"# **7. Visualization of Forecast vs Observed Data**\\n\",\n",
        "    \"\\n\",\n",
        "    \"This section visualizes the forecasted values against the observed water levels for comparison.\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": null,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"# Function to plot forecasted values against observed values\\n\",\n",
        "    \"def plot_forecast_vs_observed(results_df):\\n\",\n",
        "    \"    \\\"\\\"\\\"\\n\",\n",
        "    \"    Visualizes the observed water levels and the corresponding forecasted values for the 1st, 2nd, and 3rd days.\\n\",\n",
        "    \"    \\\"\\\"\\\"\\n\",\n",
        "    \"    plt.figure(figsize=(15, 8))\\n\",\n",
        "    \"    plt.plot(results_df['date'], results_df['obs'], label=\\\"Observed\\\", color='b')\\n\",\n",
        "    \"    plt.plot(results_df['date'], results_df['h1'], label=\\\"Forecast (Day 1)\\\", color='r')\\n\",\n",
        "    \"    plt.plot(results_df['date'], results_df['h2'], label=\\\"Forecast (Day 2)\\\", color='orange')\\n\",\n",
        "    \"    plt.plot(results_df['date'], results_df['h3'], label=\\\"Forecast (Day 3)\\\", color='green')\\n\",\n",
        "    \"    plt.xlabel(\\\"Date\\\")\\n\",\n",
        "    \"    plt.ylabel(\\\"Water Level\\\")\\n\",\n",
        "    \"    plt.title(\\\"Three-Day-Ahead TimesFM Rolling Forecast vs Observed Water Levels\\\")\\n\",\n",
        "    \"    plt.legend()\\n\",\n",
        "    \"    plt.tight_layout()\\n\",\n",
        "    \"    plt.show()\\n\",\n",
        "    \"\\n\",\n",
        "    \"# Call the plot function to display forecast vs observed comparison\\n\",\n",
        "    \"plot_forecast_vs_observed(results_df)\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"markdown\",\n",
        "   \"metadata\": {},\n",
        "   \"source\": [\n",
        "    \"# **8. Model Evaluation - Nash-Sutcliffe and Kling-Gupta Efficiency**\\n\",\n",
        "    \"\\n\",\n",
        "    \"In this section, we evaluate the performance of the forecast using two efficiency metrics: Nash-Sutcliffe Efficiency (NSE) and Kling-Gupta Efficiency (KGE).\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": null,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"# Function to calculate Nash-Sutcliffe Efficiency (NSE)\\n\",\n",
        "    \"def nse(observed, forecasted):\\n\",\n",
        "    \"    numerator = np.sum((observed - forecasted) ** 2)\\n\",\n",
        "    \"    denominator = np.sum((observed - np.mean(observed)) ** 2)\\n\",\n",
        "    \"    return 1 - (numerator / denominator)\\n\",\n",
        "    \"\\n\",\n",
        "    \"# Function to calculate Kling-Gupta Efficiency (KGE)\\n\",\n",
        "    \"def kge(observed, forecasted):\\n\",\n",
        "    \"    # Calculate correlation coefficient\\n\",\n",
        "    \"    r = np.corrcoef(observed, forecasted)[0, 1]\\n\",\n",
        "    \"\\n\",\n",
        "    \"    # Calculate variability ratio (alpha)\\n\",\n",
        "    \"    alpha = np.std(forecasted) / np.std(observed)\\n\",\n",
        "    \"\\n\",\n",
        "    \"    # Calculate bias ratio (beta)\\n\",\n",
        "    \"    beta = np.mean(forecasted) / np.mean(observed)\\n\",\n",
        "    \"\\n\",\n",
        "    \"    # Calculate KGE\\n\",\n",
        "    \"    kge_value = 1 - np.sqrt((r - 1) ** 2 + (alpha - 1) ** 2 + (beta - 1) ** 2)\\n\",\n",
        "    \"    return kge_value\\n\",\n",
        "    \"\\n\",\n",
        "    \"# Section 11: Calculate and Print NSE and KGE for Forecasts\\n\",\n",
        "    \"observed = results_df['obs'].values\\n\",\n",
        "    \"\\n\",\n",
        "    \"# Calculate NSE and KGE for the 1st day forecast (h1)\\n\",\n",
        "    \"forecasted_h1 = results_df['h1'].values\\n\",\n",
        "    \"nse_h1 = nse(observed, forecasted_h1)\\n\",\n",
        "    \"kge_h1 = kge(observed, forecasted_h1)\\n\",\n",
        "    \"\\n\",\n",
        "    \"# Print NSE and KGE values\\n\",\n",
        "    \"print(f\\\"Nash-Sutcliffe Efficiency (NSE) for 1st day forecast: {nse_h1}\\\")\\n\",\n",
        "    \"print(f\\\"Kling-Gupta Efficiency (KGE) for 1st day forecast: {kge_h1}\\\")\\n\",\n",
        "    \"\\n\",\n",
        "    \"# Repeat for the 2nd day (h2) and 3rd day (h3) forecasts\\n\",\n",
        "    \"forecasted_h2 = results_df['h2'].values\\n\",\n",
        "    \"forecasted_h3 = results_df['h3'].values\\n\",\n",
        "    \"\\n\",\n",
        "    \"nse_h2 = nse(observed, forecasted_h2)\\n\",\n",
        "    \"kge_h2 = kge(observed, forecasted_h2)\\n\",\n",
        "    \"\\n\",\n",
        "    \"nse_h3 = nse(observed, forecasted_h3)\\n\",\n",
        "    \"kge_h3 = kge(observed, forecasted_h3)\\n\",\n",
        "    \"\\n\",\n",
        "    \"# Print results for each forecast horizon\\n\",\n",
        "    \"print(f\\\"Nash-Sutcliffe Efficiency (NSE) for 2nd day forecast: {nse_h2}\\\")\\n\",\n",
        "    \"print(f\\\"Kling-Gupta Efficiency (KGE) for 2nd day forecast: {kge_h2}\\\")\\n\",\n",
        "    \"print(f\\\"Nash-Sutcliffe Efficiency (NSE) for 3rd day forecast: {nse_h3}\\\")\\n\",\n",
        "    \"print(f\\\"Kling-Gupta Efficiency (KGE) for 3rd day forecast: {kge_h3}\\\")\"\n",
        "   ]\n",
        "  }\n",
        " ]\n",
        "}"
      ]
    }
  ]
}
